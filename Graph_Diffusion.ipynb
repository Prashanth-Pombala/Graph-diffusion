{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_geometric\n",
        "!pip install matplotlib\n",
        "!pip install rdkit\n",
        "import os\n",
        "import torch\n",
        "os.environ['TORCH'] = torch.__version__\n",
        "print(torch.__version__)\n",
        "\n",
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "#!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n",
        "\n",
        "# Helper function for visualization.\n",
        "%matplotlib inline\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def visualize_graph(G, color):\n",
        "    plt.figure(figsize=(7,7))\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    nx.draw_networkx(G, pos=nx.spring_layout(G, seed=42), with_labels=False,\n",
        "                     node_color=color, cmap=\"Set2\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def visualize_embedding(h, color, epoch=None, loss=None):\n",
        "    plt.figure(figsize=(7,7))\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    h = h.detach().cpu().numpy()\n",
        "    plt.scatter(h[:, 0], h[:, 1], s=140, c=color, cmap=\"Set2\")\n",
        "    if epoch is not None and loss is not None:\n",
        "        plt.xlabel(f'Epoch: {epoch}, Loss: {loss.item():.4f}', fontsize=16)\n",
        "    plt.show()\n",
        "\n",
        "import os.path as osp\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "from torch_geometric.utils import negative_sampling\n",
        "from torch_geometric.datasets import Planetoid\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.utils import train_test_split_edges\n",
        "from torch_geometric.nn import BatchNorm, PNAConv, global_add_pool\n",
        "from torch_geometric.utils import degree"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QlIZNxwlR4gE",
        "outputId": "7ad18990-8ed4-4319-c278-680861c82258"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.5.3-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.11.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2023.6.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.9.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2024.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.5.0)\n",
            "Installing collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.5.3\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Collecting rdkit\n",
            "  Downloading rdkit-2023.9.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.9/34.9 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rdkit) (1.25.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit) (9.4.0)\n",
            "Installing collected packages: rdkit\n",
            "Successfully installed rdkit-2023.9.6\n",
            "2.3.0+cu121\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m71.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the dataset\n"
      ],
      "metadata": {
        "id": "SszG3NyAb6wt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from rdkit import Chem\n",
        "\n",
        "def load_qm9_smiles(csv_file):\n",
        "    # Read the CSV file containing the QM9 dataset\n",
        "    df = pd.read_csv(csv_file)\n",
        "\n",
        "    # Extract SMILES strings\n",
        "    smiles_list = df['smiles'].tolist()\n",
        "\n",
        "    return smiles_list\n",
        "\n",
        "\n",
        "csv_file = \"qm9.csv\"\n",
        "qm9_smiles = load_qm9_smiles(csv_file)\n",
        "def remove_hydrogen_from_smiles(smiles_list):\n",
        "    modified_smiles = []\n",
        "    for smiles in smiles_list:\n",
        "        mol = Chem.MolFromSmiles(smiles)\n",
        "        if mol is None:\n",
        "            print(\"Invalid SMILES:\", smiles)\n",
        "            continue\n",
        "        mol = Chem.RemoveHs(mol)\n",
        "        modified_smiles.append(Chem.MolToSmiles(mol))\n",
        "    return modified_smiles\n",
        "\n",
        "\n",
        "\n",
        "modified_smiles = remove_hydrogen_from_smiles(qm9_smiles)\n",
        "from torch_geometric.data import Data, DataLoader\n",
        "def smiles_to_graph(smiles):\n",
        "    # Parse the SMILES string\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    if mol is None:\n",
        "        return None, None\n",
        "\n",
        "    # Get node features (atomic numbers)\n",
        "    atomic_numbers = [atom.GetAtomicNum() for atom in mol.GetAtoms()]\n",
        "\n",
        "    # Get edge indices (connectivity)\n",
        "    edge_index = []\n",
        "    for bond in mol.GetBonds():\n",
        "        start_idx = bond.GetBeginAtomIdx()\n",
        "        end_idx = bond.GetEndAtomIdx()\n",
        "        edge_index.append([start_idx, end_idx])\n",
        "\n",
        "    # Convert edge indices to PyTorch tensor\n",
        "    edge_index = torch.tensor(edge_index).t().contiguous()\n",
        "\n",
        "    # Convert node features to PyTorch tensor\n",
        "    node_features = torch.tensor(atomic_numbers, dtype=torch.float).unsqueeze(1)\n",
        "\n",
        "    return node_features, edge_index\n",
        "filtered_dataset = []\n",
        "for smile in modified_smiles:\n",
        "\n",
        "    node_features, edge_index1 = smiles_to_graph(smile)\n",
        "    num_nodes = node_features.shape[0]\n",
        "    if num_nodes>1:\n",
        "        encoding_mappings = {7: [0, 0, 1, 0, 0],\n",
        "                     8: [0, 0, 0, 1, 0],\n",
        "                     6: [0, 1, 0, 0, 0],\n",
        "                     9: [0, 0, 0, 0, 1]}\n",
        "\n",
        "\n",
        "        one_hot_encoded = torch.tensor([encoding_mappings[num.item()] for num in node_features])\n",
        "\n",
        "\n",
        "        graph2 = Data(x=one_hot_encoded, edge_index=edge_index1, num_nodes=num_nodes)\n",
        "\n",
        "        # If the graph has more than one node, add it to the filtered dataset\n",
        "        filtered_dataset.append(graph2)\n",
        "\n"
      ],
      "metadata": {
        "id": "zRIFsdHDR4jB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model dependencies"
      ],
      "metadata": {
        "id": "ciwL4fSNcGaQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "import torch\n",
        "import math\n",
        "\n",
        "def unsorted_segment_sum(data, segment_ids, num_segments, normalization_factor, aggregation_method: str):\n",
        "    \"\"\"Custom PyTorch op to replicate TensorFlow's `unsorted_segment_sum`.\n",
        "        Normalization: 'sum' or 'mean'.\n",
        "    \"\"\"\n",
        "    result_shape = (num_segments, data.size(1))\n",
        "    result = data.new_full(result_shape, 0)  # Init empty result tensor.\n",
        "    segment_ids = segment_ids.unsqueeze(-1).expand(-1, data.size(1))\n",
        "    result.scatter_add_(0, segment_ids, data)\n",
        "    if aggregation_method == 'sum':\n",
        "        result = result / normalization_factor\n",
        "\n",
        "    if aggregation_method == 'mean':\n",
        "        norm = data.new_zeros(result.shape)\n",
        "        norm.scatter_add_(0, segment_ids, data.new_ones(data.shape))\n",
        "        norm[norm == 0] = 1\n",
        "        result = result / norm\n",
        "    return result\n",
        "\n",
        "class GCL(nn.Module):\n",
        "    def __init__(self, input_nf, output_nf, hidden_nf, normalization_factor, aggregation_method,\n",
        "                 edges_in_d=0, nodes_att_dim=0, act_fn=nn.SiLU(), attention=False):\n",
        "        super(GCL, self).__init__()\n",
        "        input_edge = input_nf * 2\n",
        "        self.normalization_factor = normalization_factor\n",
        "        self.aggregation_method = aggregation_method\n",
        "        self.attention = attention\n",
        "\n",
        "        self.edge_mlp = nn.Sequential(\n",
        "            nn.Linear(input_edge + edges_in_d, hidden_nf),\n",
        "            act_fn,\n",
        "            nn.Linear(hidden_nf, hidden_nf),\n",
        "            act_fn)\n",
        "\n",
        "        self.node_mlp = nn.Sequential(\n",
        "            nn.Linear(hidden_nf + input_nf + nodes_att_dim, hidden_nf),\n",
        "            act_fn,\n",
        "            nn.Linear(hidden_nf, output_nf))\n",
        "\n",
        "        if self.attention:\n",
        "            self.att_mlp = nn.Sequential(\n",
        "                nn.Linear(hidden_nf, 1),\n",
        "                nn.Sigmoid())\n",
        "\n",
        "    def edge_model(self, source, target, edge_attr, edge_mask):\n",
        "        if edge_attr is None:  # Unused.\n",
        "            out = torch.cat([source, target], dim=1)\n",
        "        else:\n",
        "            out = torch.cat([source, target, edge_attr], dim=1)\n",
        "\n",
        "        mij = self.edge_mlp(out)\n",
        "\n",
        "        if self.attention:\n",
        "            att_val = self.att_mlp(mij)\n",
        "            out = mij * att_val\n",
        "        else:\n",
        "            out = mij\n",
        "\n",
        "        if edge_mask is not None:\n",
        "            out = out * edge_mask\n",
        "        return out, mij\n",
        "\n",
        "    def node_model(self, x, edge_index, edge_attr, node_attr):\n",
        "        row, col = edge_index\n",
        "        agg = unsorted_segment_sum(edge_attr, row, num_segments=x.size(0),\n",
        "                                   normalization_factor=self.normalization_factor,\n",
        "                                   aggregation_method=self.aggregation_method)\n",
        "        if node_attr is not None:\n",
        "            agg = torch.cat([x, agg, node_attr], dim=1)\n",
        "        else:\n",
        "            agg = torch.cat([x, agg], dim=1)\n",
        "        out = x + self.node_mlp(agg)\n",
        "        return out, agg\n",
        "\n",
        "    def forward(self, h, edge_index, edge_attr=None, node_attr=None, node_mask=None, edge_mask=None):\n",
        "        row, col = edge_index\n",
        "        edge_feat, mij = self.edge_model(h[row], h[col], edge_attr, edge_mask)\n",
        "        h, agg = self.node_model(h, edge_index, edge_feat, node_attr)\n",
        "        if node_mask is not None:\n",
        "            h = h * node_mask\n",
        "        return h, mij\n",
        "\n",
        "class GNN(nn.Module):\n",
        "    def __init__(self, in_node_nf, in_edge_nf, hidden_nf, out_node_nf,aggregation_method='sum', device='cpu',\n",
        "                 act_fn=nn.SiLU(), n_layers=4, attention=False,\n",
        "                 normalization_factor=100, ):\n",
        "        super(GNN, self).__init__()\n",
        "        if out_node_nf is None:\n",
        "            out_node_nf = in_node_nf\n",
        "        self.hidden_nf = hidden_nf\n",
        "        self.device = device\n",
        "        self.n_layers = n_layers\n",
        "        ### Encoder\n",
        "        self.embedding = nn.Linear(in_node_nf, self.hidden_nf)\n",
        "        self.embedding_out = nn.Linear(self.hidden_nf, out_node_nf)\n",
        "        for i in range(0, n_layers):\n",
        "            self.add_module(\"gcl_%d\" % i, GCL(\n",
        "                self.hidden_nf, self.hidden_nf, self.hidden_nf,\n",
        "                normalization_factor=normalization_factor,\n",
        "                aggregation_method=aggregation_method,\n",
        "                edges_in_d=in_edge_nf, act_fn=act_fn,\n",
        "                attention=attention))\n",
        "        self.to(self.device)\n",
        "\n",
        "    def forward(self, h, edges, edge_attr=None, node_mask=None, edge_mask=None):\n",
        "        # Edit Emiel: Remove velocity as input\n",
        "        h = self.embedding(h)\n",
        "        for i in range(0, self.n_layers):\n",
        "            h, _ = self._modules[\"gcl_%d\" % i](h, edges, edge_attr=edge_attr, node_mask=node_mask, edge_mask=edge_mask)\n",
        "        h = self.embedding_out(h)\n",
        "\n",
        "        # Important, the bias of the last linear might be non-zero\n",
        "        if node_mask is not None:\n",
        "            h = h * node_mask\n",
        "        return h\n",
        "import numpy as np\n",
        "\n",
        "def fully_connected_graph_with_self_loops(num_nodes):\n",
        "    \"\"\"\n",
        "    Generates edge indices for a fully connected graph with self-loops.\n",
        "\n",
        "    Args:\n",
        "        num_nodes (int): Number of nodes in the graph.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: Edge indices of the fully connected graph with self-loops.\n",
        "    \"\"\"\n",
        "    # Create edge indices for a fully connected graph with self-loops\n",
        "    edge_index = torch.tensor([[i, j] for i in range(num_nodes) for j in range(num_nodes)])\n",
        "\n",
        "    return edge_index.t().contiguous()\n"
      ],
      "metadata": {
        "id": "wiztlcSGR4lm"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class GNN(nn.Module):\n",
        "    def __init__(self, in_node_nf, in_edge_nf, hidden_nf, out_node_nf,aggregation_method='sum', device='cpu',\n",
        "                 act_fn=nn.SiLU(), n_layers=4, attention=False,\n",
        "                 normalization_factor=100, ):\n",
        "        super(GNN, self).__init__()\n",
        "        if out_node_nf is None:\n",
        "            out_node_nf = in_node_nf\n",
        "        self.hidden_nf = hidden_nf\n",
        "        self.device = device\n",
        "        self.n_layers = n_layers\n",
        "        ### Encoder\n",
        "        self.embedding = nn.Linear(in_node_nf, self.hidden_nf)\n",
        "        self.embedding_out = nn.Linear(self.hidden_nf, out_node_nf)\n",
        "        for i in range(0, n_layers):\n",
        "            self.add_module(\"gcl_%d\" % i, GCL(\n",
        "                self.hidden_nf, self.hidden_nf, self.hidden_nf,\n",
        "                normalization_factor=normalization_factor,\n",
        "                aggregation_method=aggregation_method,\n",
        "                edges_in_d=in_edge_nf, act_fn=act_fn,\n",
        "                attention=attention))\n",
        "        self.to(self.device)\n",
        "\n",
        "    def forward(self, h, edges, edge_attr=None, node_mask=None, edge_mask=None):\n",
        "        # Edit Emiel: Remove velocity as input\n",
        "        h = self.embedding(h)\n",
        "        for i in range(0, self.n_layers):\n",
        "            h, _ = self._modules[\"gcl_%d\" % i](h, edges, edge_attr=edge_attr, node_mask=node_mask, edge_mask=edge_mask)\n",
        "        h = self.embedding_out(h)\n",
        "\n",
        "        # Important, the bias of the last linear might be non-zero\n",
        "        if node_mask is not None:\n",
        "            h = h * node_mask\n",
        "        return h\n",
        "def coord2diff(x, edge_index, norm_constant=1):\n",
        "    row, col = edge_index\n",
        "    coord_diff = x[row] - x[col]\n",
        "    radial = torch.sum((coord_diff) ** 2, 1).unsqueeze(1)\n",
        "    norm = torch.sqrt(radial + 1e-8)\n",
        "    coord_diff = coord_diff/(norm + norm_constant)\n",
        "    return radial, coord_diff\n",
        "class GCL(nn.Module):\n",
        "    def __init__(self, input_nf, output_nf, hidden_nf, normalization_factor, aggregation_method,\n",
        "                 edges_in_d=0, nodes_att_dim=0, act_fn=nn.SiLU(), attention=False):\n",
        "        super(GCL, self).__init__()\n",
        "        input_edge = input_nf * 2\n",
        "        self.normalization_factor = normalization_factor\n",
        "        self.aggregation_method = aggregation_method\n",
        "        self.attention = attention\n",
        "\n",
        "        self.edge_mlp = nn.Sequential(\n",
        "            nn.Linear(input_edge + edges_in_d, hidden_nf),\n",
        "            act_fn,\n",
        "            nn.Linear(hidden_nf, hidden_nf),\n",
        "            act_fn)\n",
        "\n",
        "        self.node_mlp = nn.Sequential(\n",
        "            nn.Linear(hidden_nf + input_nf + nodes_att_dim, hidden_nf),\n",
        "            act_fn,\n",
        "            nn.Linear(hidden_nf, output_nf))\n",
        "\n",
        "        if self.attention:\n",
        "            self.att_mlp = nn.Sequential(\n",
        "                nn.Linear(hidden_nf, 1),\n",
        "                nn.Sigmoid())\n",
        "\n",
        "    def edge_model(self, source, target, edge_attr, edge_mask):\n",
        "        if edge_attr is None:  # Unused.\n",
        "            out = torch.cat([source, target], dim=1)\n",
        "        else:\n",
        "            out = torch.cat([source, target, edge_attr], dim=1)\n",
        "        mij = self.edge_mlp(out)\n",
        "\n",
        "        if self.attention:\n",
        "            att_val = self.att_mlp(mij)\n",
        "            out = mij * att_val\n",
        "        else:\n",
        "            out = mij\n",
        "\n",
        "        if edge_mask is not None:\n",
        "            out = out * edge_mask\n",
        "        return out, mij\n",
        "\n",
        "    def node_model(self, x, edge_index, edge_attr, node_attr):\n",
        "        row, col = edge_index\n",
        "        agg = unsorted_segment_sum(edge_attr, row, num_segments=x.size(0),\n",
        "                                   normalization_factor=self.normalization_factor,\n",
        "                                   aggregation_method=self.aggregation_method)\n",
        "        if node_attr is not None:\n",
        "            agg = torch.cat([x, agg, node_attr], dim=1)\n",
        "        else:\n",
        "            agg = torch.cat([x, agg], dim=1)\n",
        "        out = x + self.node_mlp(agg)\n",
        "        return out, agg\n",
        "\n",
        "    def forward(self, h, edge_index, edge_attr=None, node_attr=None, node_mask=None, edge_mask=None):\n",
        "        row, col = edge_index\n",
        "        edge_feat, mij = self.edge_model(h[row], h[col], edge_attr, edge_mask)\n",
        "        h, agg = self.node_model(h, edge_index, edge_feat, node_attr)\n",
        "        if node_mask is not None:\n",
        "            h = h * node_mask\n",
        "        return h, mij\n",
        "\n",
        "\n",
        "class EquivariantUpdate(nn.Module):\n",
        "    def __init__(self, hidden_nf, normalization_factor, aggregation_method,\n",
        "                 edges_in_d=1, act_fn=nn.SiLU(), tanh=False, coords_range=10.0):\n",
        "        super(EquivariantUpdate, self).__init__()\n",
        "        self.tanh = tanh\n",
        "        self.coords_range = coords_range\n",
        "        input_edge = hidden_nf * 2 + edges_in_d\n",
        "        layer = nn.Linear(hidden_nf, 1, bias=False)\n",
        "        torch.nn.init.xavier_uniform_(layer.weight, gain=0.001)\n",
        "        self.coord_mlp = nn.Sequential(\n",
        "            nn.Linear(input_edge, hidden_nf),\n",
        "            act_fn,\n",
        "            nn.Linear(hidden_nf, hidden_nf),\n",
        "            act_fn,\n",
        "            layer)\n",
        "        self.normalization_factor = normalization_factor\n",
        "        self.aggregation_method = aggregation_method\n",
        "\n",
        "    def coord_model(self, h, coord, edge_index, coord_diff, edge_attr, edge_mask):\n",
        "        row, col = edge_index\n",
        "        input_tensor = torch.cat([h[row], h[col], edge_attr], dim=1)\n",
        "        if self.tanh:\n",
        "            trans = coord_diff * torch.tanh(self.coord_mlp(input_tensor)) * self.coords_range\n",
        "        else:\n",
        "            trans = coord_diff * self.coord_mlp(input_tensor)\n",
        "        if edge_mask is not None:\n",
        "            trans = trans * edge_mask\n",
        "        agg = unsorted_segment_sum(trans, row, num_segments=coord.size(0),\n",
        "                                   normalization_factor=self.normalization_factor,\n",
        "                                   aggregation_method=self.aggregation_method)\n",
        "        coord = coord + agg\n",
        "        return coord\n",
        "\n",
        "    def forward(self, h, coord, edge_index, coord_diff, edge_attr=None, node_mask=None, edge_mask=None):\n",
        "        coord = self.coord_model(h, coord, edge_index, coord_diff, edge_attr, edge_mask)\n",
        "        if node_mask is not None:\n",
        "            coord = coord * node_mask\n",
        "        return coord\n",
        "\n",
        "\n",
        "class EquivariantBlock(nn.Module):\n",
        "    def __init__(self, hidden_nf, edge_feat_nf=2, device='cpu', act_fn=nn.SiLU(), n_layers=2, attention=True,\n",
        "                 norm_diff=True, tanh=False, coords_range=15, norm_constant=1, sin_embedding=None,\n",
        "                 normalization_factor=100, aggregation_method='sum'):\n",
        "        super(EquivariantBlock, self).__init__()\n",
        "        self.hidden_nf = hidden_nf\n",
        "        self.device = device\n",
        "        self.n_layers = n_layers\n",
        "        self.coords_range_layer = float(coords_range)\n",
        "        self.norm_diff = norm_diff\n",
        "        self.norm_constant = norm_constant\n",
        "        self.sin_embedding = sin_embedding\n",
        "        self.normalization_factor = normalization_factor\n",
        "        self.aggregation_method = aggregation_method\n",
        "\n",
        "        for i in range(0, n_layers):\n",
        "            self.add_module(\"gcl_%d\" % i, GCL(self.hidden_nf, self.hidden_nf, self.hidden_nf, edges_in_d=edge_feat_nf,\n",
        "                                              act_fn=act_fn, attention=attention,\n",
        "                                              normalization_factor=self.normalization_factor,\n",
        "                                              aggregation_method=self.aggregation_method))\n",
        "        self.add_module(\"gcl_equiv\", EquivariantUpdate(hidden_nf, edges_in_d=edge_feat_nf, act_fn=nn.SiLU(), tanh=tanh,\n",
        "                                                       coords_range=self.coords_range_layer,\n",
        "                                                       normalization_factor=self.normalization_factor,\n",
        "                                                       aggregation_method=self.aggregation_method))\n",
        "        self.to(self.device)\n",
        "\n",
        "    def forward(self, h, x, edge_index, node_mask=None, edge_mask=None, edge_attr=None):\n",
        "        # Edit Emiel: Remove velocity as input\n",
        "        distances, coord_diff = coord2diff(x, edge_index, self.norm_constant)\n",
        "        if self.sin_embedding is not None:\n",
        "            distances = self.sin_embedding(distances)\n",
        "        edge_attr = torch.cat([distances, edge_attr], dim=1)\n",
        "        for i in range(0, self.n_layers):\n",
        "            h, _ = self._modules[\"gcl_%d\" % i](h, edge_index, edge_attr=edge_attr, node_mask=node_mask, edge_mask=edge_mask)\n",
        "        x = self._modules[\"gcl_equiv\"](h, x, edge_index, coord_diff, edge_attr, node_mask, edge_mask)\n",
        "\n",
        "        # Important, the bias of the last linear might be non-zero\n",
        "        if node_mask is not None:\n",
        "            h = h * node_mask\n",
        "        return h, x\n",
        "\n",
        "\n",
        "class EGNN(nn.Module):\n",
        "    def __init__(self, in_node_nf, in_edge_nf, hidden_nf, device='cpu', act_fn=nn.SiLU(), n_layers=3, attention=False,\n",
        "                 norm_diff=True, out_node_nf=None, tanh=False, coords_range=15, norm_constant=1, inv_sublayers=2,\n",
        "                 sin_embedding=False, normalization_factor=100, aggregation_method='sum'):\n",
        "        super(EGNN, self).__init__()\n",
        "        if out_node_nf is None:\n",
        "            out_node_nf = in_node_nf\n",
        "        self.hidden_nf = hidden_nf\n",
        "        self.device = device\n",
        "        self.n_layers = n_layers\n",
        "        self.coords_range_layer = float(coords_range/n_layers) if n_layers > 0 else float(coords_range)\n",
        "        self.norm_diff = norm_diff\n",
        "        self.normalization_factor = normalization_factor\n",
        "        self.aggregation_method = aggregation_method\n",
        "\n",
        "        if sin_embedding:\n",
        "            self.sin_embedding = SinusoidsEmbeddingNew()\n",
        "            edge_feat_nf = self.sin_embedding.dim * 2\n",
        "        else:\n",
        "            self.sin_embedding = None\n",
        "            edge_feat_nf = 2\n",
        "\n",
        "        self.embedding = nn.Linear(in_node_nf, self.hidden_nf)\n",
        "        self.embedding_out = nn.Linear(self.hidden_nf, out_node_nf)\n",
        "        for i in range(0, n_layers):\n",
        "            self.add_module(\"e_block_%d\" % i, EquivariantBlock(hidden_nf, edge_feat_nf=edge_feat_nf, device=device,\n",
        "                                                               act_fn=act_fn, n_layers=inv_sublayers,\n",
        "                                                               attention=attention, norm_diff=norm_diff, tanh=tanh,\n",
        "                                                               coords_range=coords_range, norm_constant=norm_constant,\n",
        "                                                               sin_embedding=self.sin_embedding,\n",
        "                                                               normalization_factor=self.normalization_factor,\n",
        "                                                               aggregation_method=self.aggregation_method))\n",
        "        self.to(self.device)\n",
        "\n",
        "    def forward(self, h, x, edge_index, node_mask=None, edge_mask=None):\n",
        "        # Edit Emiel: Remove velocity as input\n",
        "        distances, _ = coord2diff(x, edge_index)\n",
        "        if self.sin_embedding is not None:\n",
        "            distances = self.sin_embedding(distances)\n",
        "        h = self.embedding(h)\n",
        "        for i in range(0, self.n_layers):\n",
        "            h, x = self._modules[\"e_block_%d\" % i](h, x, edge_index, node_mask=node_mask, edge_mask=edge_mask, edge_attr=distances)\n",
        "\n",
        "        # Important, the bias of the last linear might be non-zero\n",
        "        h = self.embedding_out(h)\n",
        "        if node_mask is not None:\n",
        "            h = h * node_mask\n",
        "        return h, x\n"
      ],
      "metadata": {
        "id": "OOKDp_D9R4oT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Autoencoder model"
      ],
      "metadata": {
        "id": "tSq8biIicCyS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.loader import DataLoader\n",
        "\n",
        "from torch.nn import Linear\n",
        "from torch_geometric.nn import PNAConv\n",
        "# Initialize the autoencoder model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class GraphAutoencoder(nn.Module):\n",
        "   def __init__(self):\n",
        "        super(GraphAutoencoder, self).__init__()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        in_edge_nf = 0  # Replace with the actual input edge feature dimension\n",
        "\n",
        "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "        act_fn = torch.nn.SiLU()\n",
        "        n_layers = 4  # Replace with the desired number of layers\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        self.conv1 = GNN(\n",
        "                    in_node_nf=5,\n",
        "                    in_edge_nf=in_edge_nf,\n",
        "                    hidden_nf=8,\n",
        "                    out_node_nf= 2,\n",
        "                    device=device,\n",
        "                    act_fn=act_fn,\n",
        "                    n_layers=n_layers\n",
        "        )\n",
        "\n",
        "\n",
        "        self.dconv1 = GNN(\n",
        "                    in_node_nf=2,\n",
        "                    in_edge_nf=in_edge_nf,\n",
        "                    hidden_nf=8,\n",
        "                    out_node_nf= 5,\n",
        "                    device=device,\n",
        "                    act_fn=act_fn,\n",
        "                    n_layers=n_layers\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "   def encode(self,x,edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "\n",
        "\n",
        "        return x\n",
        "\n",
        "   def decode(self, z, edge_index): # only pos and neg edges\n",
        "        z = self.dconv1(z, edge_index)\n",
        "\n",
        "\n",
        "        return z\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "epochs = 50\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "\n",
        "model= GraphAutoencoder()\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.001)\n",
        "\n",
        "criterion = criterion = nn.MSELoss()\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "oktbX9jeR4qh"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parameters of the forward diffusion process\n"
      ],
      "metadata": {
        "id": "KH9kO-e8cQE7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cosine_beta_schedule(timesteps, s=0.008):\n",
        "    \"\"\"\n",
        "    cosine schedule as proposed in https://arxiv.org/abs/2102.09672\n",
        "    \"\"\"\n",
        "    steps = timesteps + 1\n",
        "    x = torch.linspace(0, timesteps, steps)\n",
        "    alphas_cumprod = torch.cos(((x / timesteps) + s) / (1 + s) * torch.pi * 0.5) ** 2\n",
        "    alphas_cumprod = alphas_cumprod / alphas_cumprod[0]\n",
        "    betas = 1 - (alphas_cumprod[1:] / alphas_cumprod[:-1])\n",
        "    return torch.clip(betas, 0.0001, 0.9999)\n",
        "\n",
        "def linear_beta_schedule(timesteps):\n",
        "    beta_start = 0.0001\n",
        "    beta_end = 0.02\n",
        "    return torch.linspace(beta_start, beta_end, timesteps)\n",
        "\n",
        "def quadratic_beta_schedule(timesteps):\n",
        "    beta_start = 0.0001\n",
        "    beta_end = 0.02\n",
        "    return torch.linspace(beta_start**0.5, beta_end**0.5, timesteps) ** 2\n",
        "\n",
        "def sigmoid_beta_schedule(timesteps):\n",
        "    beta_start = 0.0001\n",
        "    beta_end = 0.02\n",
        "    betas = torch.linspace(-6, 6, timesteps)\n",
        "    return torch.sigmoid(betas) * (beta_end - beta_start) + beta_start\n",
        "timesteps = 50\n",
        "\n",
        "# define beta schedule\n",
        "betas = linear_beta_schedule(timesteps=timesteps)\n",
        "\n",
        "\n",
        "# define alphas\n",
        "alphas = 1. - betas\n",
        "\n",
        "alphas_cumprod = torch.cumprod(alphas, axis=0)\n",
        "alphas_cumprod_prev = F.pad(alphas_cumprod[:-1], (1, 0), value=1.0)\n",
        "sqrt_recip_alphas = torch.sqrt(1.0 / alphas)\n",
        "\n",
        "# calculations for diffusion q(x_t | x_{t-1}) and others\n",
        "sqrt_alphas_cumprod = torch.sqrt(alphas_cumprod)\n",
        "sqrt_one_minus_alphas_cumprod = torch.sqrt(1. - alphas_cumprod)\n",
        "\n",
        "# calculations for posterior q(x_{t-1} | x_t, x_0)\n",
        "posterior_variance = betas * (1. - alphas_cumprod_prev) / (1. - alphas_cumprod)\n",
        "\n",
        "def extract(a, t, x_shape):\n",
        "    batch_size = t.shape[0]\n",
        "    out = a.gather(-1, t.cpu())\n",
        "    return out.reshape(batch_size, *((1,) * (len(x_shape) - 1))).to(t.device)\n",
        "# forward diffusion\n",
        "def q_sample(x_start, t, noise=None):\n",
        "    if noise is None:\n",
        "        noise = torch.randn_like(x_start)\n",
        "\n",
        "    sqrt_alphas_cumprod_t = extract(sqrt_alphas_cumprod, t, x_start.shape)\n",
        "    sqrt_one_minus_alphas_cumprod_t = extract(\n",
        "        sqrt_one_minus_alphas_cumprod, t, x_start.shape\n",
        "    )\n",
        "\n",
        "    return sqrt_alphas_cumprod_t.to(device) * x_start.to(device) + sqrt_one_minus_alphas_cumprod_t.to(device) * noise.to(device), noise.to(device)\n",
        "def get_noisy_image(x_start, t):\n",
        "  # add noise\n",
        "  x_noisy,tar_noise = q_sample(x_start, t=t)\n",
        "\n",
        "\n",
        "  # turn back into PIL image\n",
        "\n",
        "\n",
        "  return x_noisy,tar_noise\n",
        ""
      ],
      "metadata": {
        "id": "KWQfxYlqR4tI"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the Autoencoder\n"
      ],
      "metadata": {
        "id": "_PVn_MO2cWi4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs =10\n",
        "data1= filtered_dataset[:1000]\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "for epoch in range(epochs):\n",
        "    total_loss = 0\n",
        "\n",
        "\n",
        "\n",
        "    print(epoch)\n",
        "\n",
        "    for data in data1:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        edge_index_1 = data.edge_index\n",
        "        node_features_1 = data.x\n",
        "        num_nodes_1 = node_features_1.size(0)\n",
        "        adjacency_matrix_1 = torch.zeros((num_nodes_1, num_nodes_1), dtype=torch.int)\n",
        "        for i in range(edge_index_1.size(1)):\n",
        "            source_node_1 = edge_index_1[0, i].item()\n",
        "            target_node_1 = edge_index_1[1, i].item()\n",
        "            adjacency_matrix_1[source_node_1, target_node_1] = 1\n",
        "\n",
        "\n",
        "\n",
        "        num_vectors_1 = node_features_1.size(0)\n",
        "        num_upper_triangle_terms_1 = int((num_vectors_1 * (num_vectors_1 - 1)) / 2)\n",
        "\n",
        "        pairwise_distances_1 = torch.zeros(num_upper_triangle_terms_1)\n",
        "\n",
        "        k= 0\n",
        "        # Calculate pairwise distances\n",
        "        for i in range(num_vectors_1):\n",
        "            for j in range(i + 1, num_vectors_1):\n",
        "\n",
        "\n",
        "                pairwise_distances_1[k] = adjacency_matrix_1[i][j]\n",
        "\n",
        "                k=k+ 1\n",
        "\n",
        "\n",
        "\n",
        "        pairwise_distances_1 = pairwise_distances_1.view(-1, 1)\n",
        "        pairwise_distances_1= torch.where(pairwise_distances_1 == 0, -1, pairwise_distances_1)\n",
        "\n",
        "\n",
        "        column_tensor_1 = pairwise_distances_1\n",
        "\n",
        "        num_repeats_1 = 5\n",
        "\n",
        "\n",
        "        row_tensor_1 = column_tensor_1.repeat(1, num_repeats_1)\n",
        "\n",
        "        updated_node_features_1 = torch.cat([node_features_1, row_tensor_1], dim=0)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # Initialize an empty matrix to store pairwise distances\n",
        "        num_vectors = data.x.size(0)\n",
        "        num_upper_triangle_terms = int((num_vectors * (num_vectors - 1)) / 2)\n",
        "        matrix = torch.zeros(num_vectors+ num_upper_triangle_terms, num_vectors+ num_upper_triangle_terms)\n",
        "\n",
        "\n",
        "        k= 0\n",
        "        # Calculate pairwise distances\n",
        "        for i in range(num_vectors):\n",
        "            for j in range(i + 1, num_vectors):\n",
        "                matrix[i,num_vectors+ k] = 1\n",
        "                matrix[j,num_vectors+ k] = 1\n",
        "                matrix[num_vectors+ k,i] = 1\n",
        "                matrix[num_vectors+ k,j] = 1\n",
        "\n",
        "\n",
        "\n",
        "                k=k+ 1\n",
        "                # Symmetric matrix\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        adjacency_matrix = matrix\n",
        "\n",
        "\n",
        "\n",
        "        # Get the number of nodes (assumes the adjacency matrix is square)\n",
        "        num_nodes = adjacency_matrix.size(0)\n",
        "\n",
        "        # Initialize empty lists to store the edge indices\n",
        "        updated_edge_index = [[], []]\n",
        "\n",
        "        # Iterate through the adjacency matrix\n",
        "        for i in range(num_nodes):\n",
        "            for j in range(num_nodes):\n",
        "                if adjacency_matrix[i, j] == 1:\n",
        "                    updated_edge_index[0].append(i)  # Source node\n",
        "                    updated_edge_index[1].append(j)  # Target node\n",
        "\n",
        "        # Convert the edge_index lists to tensors\n",
        "        edge_index = torch.tensor(updated_edge_index)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "\n",
        "\n",
        "        updated_node_features_1 = updated_node_features_1.to(device)\n",
        "        edge_index = edge_index.to(device)\n",
        "\n",
        "        x = model.encode(updated_node_features_1, edge_index)\n",
        "\n",
        "\n",
        "        v=x.to(device)\n",
        "\n",
        "\n",
        "\n",
        "        d= model.decode(v,edge_index)\n",
        "        d=d.unsqueeze(0)\n",
        "        updated_node_features_1= updated_node_features_1.unsqueeze(0)\n",
        "        loss= criterion(updated_node_features_1,d)\n",
        "\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    average_loss = total_loss /len(data1)\n",
        "\n",
        "\n",
        "    print(f\"Epoch [{epoch + 1}/{epochs}] Loss: {average_loss:.4f}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CfjZc4d5T49D",
        "outputId": "3c156621-c92d-40dd-d494-0b366837af65"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "Epoch [1/10] Loss: 0.0094\n",
            "1\n",
            "Epoch [2/10] Loss: 0.0093\n",
            "2\n",
            "Epoch [3/10] Loss: 0.0083\n",
            "3\n",
            "Epoch [4/10] Loss: 0.0009\n",
            "4\n",
            "Epoch [5/10] Loss: 0.0006\n",
            "5\n",
            "Epoch [6/10] Loss: 0.0005\n",
            "6\n",
            "Epoch [7/10] Loss: 0.0005\n",
            "7\n",
            "Epoch [8/10] Loss: 0.0004\n",
            "8\n",
            "Epoch [9/10] Loss: 0.0004\n",
            "9\n",
            "Epoch [10/10] Loss: 0.0004\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save the model and load it\n"
      ],
      "metadata": {
        "id": "Qeq-fWlPcalO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Save the model\n",
        "with open('autoencoder.pickle', 'wb') as model_file:\n",
        "    pickle.dump(model, model_file)\n"
      ],
      "metadata": {
        "id": "Owh3KjHtX5Nx"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sys import path\n",
        "import pickle\n",
        "\n",
        "path=  'autoencoder.pickle'\n",
        "with open(path, 'rb') as file:\n",
        "      loaded_auto = pickle.load(file)"
      ],
      "metadata": {
        "id": "bLk66CZ7X5R9"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The denoiser model\n"
      ],
      "metadata": {
        "id": "jSXBVS-Tcfpj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.utils import add_self_loops\n",
        "from torch_geometric.loader import DataLoader\n",
        "\n",
        "\n",
        "in_node_nf = 3\n",
        "out_node_nf = 3\n",
        "in_edge_nf = 0\n",
        "hidden_nf = 64\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "act_fn = torch.nn.SiLU()\n",
        "n_layers = 7\n",
        "\n",
        "\n",
        "\n",
        "# Instantiate the GNN model\n",
        "model = GNN(\n",
        "    in_node_nf=in_node_nf,\n",
        "    in_edge_nf=in_edge_nf,\n",
        "    hidden_nf=hidden_nf,\n",
        "    out_node_nf= out_node_nf,\n",
        "    device=device,\n",
        "    act_fn=act_fn,\n",
        "    n_layers=n_layers\n",
        ")\n",
        "\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "id": "TaFVIHxLYa2_"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Denoiser training"
      ],
      "metadata": {
        "id": "w3FER35gciJn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "epochs =10\n",
        "data1= filtered_dataset[:1000]\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "for epoch in range(epochs):\n",
        "    total_loss = 0\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    print(epoch)\n",
        "\n",
        "    for data in data1:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        edge_index_1 = data.edge_index\n",
        "        node_features_1 = data.x\n",
        "        num_nodes_1 = node_features_1.size(0)\n",
        "        adjacency_matrix_1 = torch.zeros((num_nodes_1, num_nodes_1), dtype=torch.int)\n",
        "        for i in range(edge_index_1.size(1)):\n",
        "            source_node_1 = edge_index_1[0, i].item()\n",
        "            target_node_1 = edge_index_1[1, i].item()\n",
        "            adjacency_matrix_1[source_node_1, target_node_1] = 1\n",
        "\n",
        "\n",
        "\n",
        "        num_vectors_1 = node_features_1.size(0)\n",
        "        num_upper_triangle_terms_1 = int((num_vectors_1 * (num_vectors_1 - 1)) / 2)\n",
        "\n",
        "        pairwise_distances_1 = torch.zeros(num_upper_triangle_terms_1)\n",
        "\n",
        "        k= 0\n",
        "        # Calculate pairwise distances\n",
        "        for i in range(num_vectors_1):\n",
        "            for j in range(i + 1, num_vectors_1):\n",
        "\n",
        "\n",
        "                pairwise_distances_1[k] = adjacency_matrix_1[i][j]\n",
        "\n",
        "                k=k+ 1\n",
        "\n",
        "\n",
        "\n",
        "        pairwise_distances_1 = pairwise_distances_1.view(-1, 1)\n",
        "        pairwise_distances_1= torch.where(pairwise_distances_1 == 0, -1, pairwise_distances_1)\n",
        "\n",
        "\n",
        "        column_tensor_1 = pairwise_distances_1\n",
        "\n",
        "        num_repeats_1 = 5\n",
        "\n",
        "        row_tensor_1 = column_tensor_1.repeat(1, num_repeats_1)\n",
        "\n",
        "\n",
        "\n",
        "        updated_node_features_1 = torch.cat([node_features_1, row_tensor_1], dim=0)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        num_vectors = data.x.size(0)\n",
        "        num_upper_triangle_terms = int((num_vectors * (num_vectors - 1)) / 2)\n",
        "        matrix = torch.zeros(num_vectors+ num_upper_triangle_terms, num_vectors+ num_upper_triangle_terms)\n",
        "\n",
        "\n",
        "        k= 0\n",
        "\n",
        "        for i in range(num_vectors):\n",
        "            for j in range(i + 1, num_vectors):\n",
        "                matrix[i,num_vectors+ k] = 1\n",
        "                matrix[j,num_vectors+ k] = 1\n",
        "                matrix[num_vectors+ k,i] = 1\n",
        "                matrix[num_vectors+ k,j] = 1\n",
        "\n",
        "\n",
        "\n",
        "                k=k+ 1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        adjacency_matrix = matrix\n",
        "\n",
        "\n",
        "\n",
        "        # Get the number of nodes (assumes the adjacency matrix is square)\n",
        "        num_nodes = adjacency_matrix.size(0)\n",
        "\n",
        "        # Initialize empty lists to store the edge indices\n",
        "        updated_edge_index = [[], []]\n",
        "\n",
        "        # Iterate through the adjacency matrix\n",
        "        for i in range(num_nodes):\n",
        "            for j in range(num_nodes):\n",
        "                if adjacency_matrix[i, j] == 1:\n",
        "                    updated_edge_index[0].append(i)  # Source node\n",
        "                    updated_edge_index[1].append(j)  # Target node\n",
        "\n",
        "        # Convert the edge_index lists to tensors\n",
        "        edge_index = torch.tensor(updated_edge_index)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "\n",
        "\n",
        "        updated_node_features_1 = updated_node_features_1.to(device)\n",
        "        edge_index = edge_index.to(device)\n",
        "\n",
        "        x = loaded_auto.encode(updated_node_features_1, edge_index)\n",
        "\n",
        "        v=x.to(device)\n",
        "\n",
        "\n",
        "\n",
        "        random_timestep = torch.randint(1, 50, size=(1,))\n",
        "\n",
        "        t = torch.tensor([random_timestep])\n",
        "\n",
        "\n",
        "        h_time = torch.empty_like(x[:, 0:1]).fill_(t.item()/50)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        original_tensor = x\n",
        "\n",
        "\n",
        "        ans,tar_noise= get_noisy_image(original_tensor, t)\n",
        "\n",
        "        num_nodes1=ans.shape[0]\n",
        "\n",
        "\n",
        "        edge_index1 = fully_connected_graph_with_self_loops(num_nodes1).to(device)\n",
        "        s= torch.cat([ans,h_time ], dim=1)\n",
        "        #if using EGNN\n",
        "        #g,output = model.denoise(h_time,ans, edge_index1)\n",
        "        #new_z = output-ans\n",
        "\n",
        "\n",
        "        d= model(s,edge_index1)\n",
        "\n",
        "        new_z = d-s\n",
        "        new_z=new_z[:, :2]\n",
        "\n",
        "\n",
        "        loss= criterion(new_z, tar_noise)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "\n",
        "\n",
        "    average_loss = total_loss /len(data1)\n",
        "\n",
        "\n",
        "    print(f\"Epoch [{epoch + 1}/{epochs}] Loss: {average_loss:.4f}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HiBTzioTT4_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Save the model\n",
        "with open('denoiser.pickle', 'wb') as model_file:\n",
        "    pickle.dump(model, model_file)\n"
      ],
      "metadata": {
        "id": "-Cjb89X8T5CH"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sys import path\n",
        "import pickle\n",
        "\n",
        "path=  'denoiser.pickle'\n",
        "with open(path, 'rb') as file:\n",
        "      loaded_deno = pickle.load(file)"
      ],
      "metadata": {
        "id": "e4IH7XbiT5Em"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import operator\n",
        "from itertools import chain, product\n",
        "from functools import partial\n",
        "from pathlib import Path\n",
        "from typing import Any, Optional, Callable, Tuple, Dict, Sequence, NamedTuple\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import Tensor, LongTensor"
      ],
      "metadata": {
        "id": "AwTieFlvT5HD"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "sampling\n"
      ],
      "metadata": {
        "id": "vRlZfrCGcl4w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#come here\n",
        "@torch.no_grad()\n",
        "def p_sample(model, data, t, t_index):\n",
        "    t1 = t_index\n",
        "    h_time = torch.empty_like(data[:, 0:1]).fill_(t1/50)\n",
        "\n",
        "    ans = data\n",
        "\n",
        "\n",
        "\n",
        "    num_nodes1=ans.shape[0]\n",
        "    edge_index1 = fully_connected_graph_with_self_loops(num_nodes1).to(device)\n",
        "    s= torch.cat([ans,h_time ], dim=1)\n",
        "\n",
        "    #g,output = loaded_deno(h_time,ans, edge_index1)\n",
        "    #new_z= output-ans\n",
        "\n",
        "    d= loaded_deno(s,edge_index1)\n",
        "\n",
        "\n",
        "\n",
        "    new_z = d-s\n",
        "    new_z=new_z[:, :2]\n",
        "\n",
        "\n",
        "\n",
        "    betas_t = extract(betas, t, ans.shape)\n",
        "\n",
        "    sqrt_one_minus_alphas_cumprod_t = extract(\n",
        "        sqrt_one_minus_alphas_cumprod, t,ans.shape\n",
        "    )\n",
        "    sqrt_recip_alphas_t = extract(sqrt_recip_alphas, t, ans.shape)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    model_mean = sqrt_recip_alphas_t * (\n",
        "        ans - betas_t * new_z / sqrt_one_minus_alphas_cumprod_t\n",
        "    )\n",
        "\n",
        "    if t_index == 0:\n",
        "        return model_mean,model_mean\n",
        "    else:\n",
        "        posterior_variance_t = extract(posterior_variance, t, ans.shape)\n",
        "        noise = torch.randn_like(ans)\n",
        "\n",
        "        return model_mean + torch.sqrt(posterior_variance_t) * noise,model_mean\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def p_sample_loop(model,data):\n",
        "    device = next(model.parameters()).device\n",
        "\n",
        "    b = 1\n",
        "\n",
        "    t_init= torch.tensor([49])\n",
        "    imgs0=[]\n",
        "    imgs = []\n",
        "    features,tar= get_noisy_image(data, t_init)\n",
        "    data= data\n",
        "\n",
        "\n",
        "    for i in tqdm(reversed(range(0, 50)), desc='sampling loop time step', total=50):\n",
        "\n",
        "\n",
        "        data,data0 = p_sample(model, data, torch.full((b,), i, device=device, dtype=torch.long), i)\n",
        "\n",
        "        imgs.append(data.cpu().numpy())\n",
        "        imgs0.append(data0.cpu().numpy())\n",
        "\n",
        "    return imgs, imgs0\n",
        "\n",
        "@torch.no_grad()\n",
        "def sample(model, data):\n",
        "    return p_sample_loop(model, data)"
      ],
      "metadata": {
        "id": "UjV8JhEoZMX6"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generating Molecules\n"
      ],
      "metadata": {
        "id": "4RFY3ic2cp2y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "real_num=4"
      ],
      "metadata": {
        "id": "rO-x91wSZRmy"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "view_samples0=[]\n",
        "view_samples=[]\n",
        "view_initial=[]\n",
        "view_final=[]\n",
        "for i in range(1):\n",
        "    num_vectors=real_num\n",
        "    num_vectors = real_num\n",
        "    num_upper_triangle_terms = int((num_vectors * (num_vectors - 1)) / 2)\n",
        "    matrix = torch.zeros(num_vectors+ num_upper_triangle_terms, num_vectors+ num_upper_triangle_terms)\n",
        "\n",
        "\n",
        "    k= 0\n",
        "    # Calculate pairwise distances\n",
        "    for i in range(num_vectors):\n",
        "        for j in range(i + 1, num_vectors):\n",
        "            matrix[i,num_vectors+ k] = 1\n",
        "            matrix[j,num_vectors+ k] = 1\n",
        "            matrix[num_vectors+ k,i] = 1\n",
        "            matrix[num_vectors+ k,j] = 1\n",
        "\n",
        "\n",
        "\n",
        "            k=k+ 1\n",
        "\n",
        "    adjacency_matrix = matrix\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    num_nodes = adjacency_matrix.size(0)\n",
        "\n",
        "\n",
        "    updated_edge_index = [[], []]\n",
        "\n",
        "\n",
        "    for i in range(num_nodes):\n",
        "        for j in range(num_nodes):\n",
        "            if adjacency_matrix[i, j] == 1:\n",
        "                updated_edge_index[0].append(i)  # Source node\n",
        "                updated_edge_index[1].append(j)  # Target node\n",
        "\n",
        "\n",
        "    edge_index = torch.tensor(updated_edge_index).to(device)\n",
        "    n_nodes= num_nodes\n",
        "    data2=torch.randn(10,2).to(device)\n",
        "    view_initial.append(data2)\n",
        "\n",
        "    samples,samples0 = sample(model, data2)\n",
        "    final=samples[49]\n",
        "    final=torch.tensor(final)\n",
        "    view_samples.append(samples)\n",
        "    view_samples0.append(samples0)\n",
        "    view_final.append(final)\n",
        "    recon= loaded_auto.decode(final.to(device),edge_index)\n",
        "    edgey= edge_index\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    des= recon[:num_vectors]\n",
        "    ans= des[:,:5]\n",
        "\n",
        "    max_values, _ = torch.max(ans, dim=1, keepdim=True)\n",
        "\n",
        "\n",
        "    ans_binary = torch.where(ans == max_values, torch.tensor(1.0), torch.tensor(0.0))\n",
        "\n",
        "    print(\"Result:\")\n",
        "    print(ans_binary)\n",
        "\n",
        "    row_values = []\n",
        "\n",
        "    # Iterate over the rows of the tensor\n",
        "    for row in ans_binary:\n",
        "        # Convert the row to a binary string\n",
        "        binary_str = ''.join([str(int(x)) for x in row.tolist()])\n",
        "        # Map the binary string to the corresponding row value\n",
        "        if binary_str == '01000':\n",
        "            row_values.append(6)\n",
        "\n",
        "        elif binary_str == '00100':\n",
        "            row_values.append(7)\n",
        "        elif binary_str == '00010':\n",
        "            row_values.append(8)\n",
        "        elif binary_str == '00001':\n",
        "            row_values.append(9)\n",
        "        else:\n",
        "            # If the binary string doesn't match any condition, append 0\n",
        "            row_values.append(0)\n",
        "\n",
        "    # Convert the list of row values to a tensor\n",
        "    new_tensor = torch.tensor(row_values)\n",
        "\n",
        "    print(\"New Tensor:\")\n",
        "    print(new_tensor)\n",
        "    augmented_features_matrix = recon\n",
        "\n",
        "    node_features_matrix = augmented_features_matrix[:num_vectors, :]\n",
        "    edge_features_matrix = augmented_features_matrix[num_vectors:, :]  # Extract edge features\n",
        "    row_averages = torch.mean(edge_features_matrix, dim=1)\n",
        "    row_averages = (row_averages > 0).float()\n",
        "\n",
        "\n",
        "    adjacency_matrix_dec = torch.zeros((num_vectors, num_vectors), dtype=torch.int)\n",
        "\n",
        "    k= 0\n",
        "\n",
        "    for i in range(num_vectors):\n",
        "        for j in range(i + 1, num_vectors):\n",
        "            adjacency_matrix_dec[i][j]=row_averages[k]\n",
        "            adjacency_matrix_dec[j][i]=row_averages[k]\n",
        "\n",
        "\n",
        "\n",
        "            k=k+ 1\n",
        "    print(adjacency_matrix_dec)\n",
        "\n",
        "    edge_list = [(i, j) for i in range(adjacency_matrix_dec.size(0)) for j in range(adjacency_matrix_dec.size(1)) if adjacency_matrix_dec[i][j] != 0]\n",
        "\n",
        "\n",
        "    edge_index = torch.tensor(edge_list).t().contiguous()\n",
        "\n",
        "    print(\"Edge Index:\")\n",
        "    print(edge_index)\n",
        "\n",
        "\n",
        "    import torch\n",
        "    from rdkit import Chem\n",
        "\n",
        "\n",
        "\n",
        "    # Convert node features and edge index to an RDKit Mol object\n",
        "    mol = Chem.RWMol()\n",
        "\n",
        "    # Keep track of the bonds already added to avoid duplicates\n",
        "    added_bonds = set()\n",
        "\n",
        "    # Add atoms to the molecule based on node features (data.x)\n",
        "    for atom_type in new_tensor:\n",
        "        atom = Chem.Atom(atom_type.item())\n",
        "        mol.AddAtom(atom)\n",
        "\n",
        "    # Add bonds to the molecule based on edge connections (data.edge_index)\n",
        "    for i, j in edge_index.t().tolist():\n",
        "        # Check if the bond already exists\n",
        "        if (i, j) not in added_bonds:\n",
        "            mol.AddBond(i, j, Chem.BondType.SINGLE)\n",
        "            added_bonds.add((i, j))\n",
        "            added_bonds.add((j, i))  # Assuming the graph is undirected\n",
        "\n",
        "    # Convert the RDKit Mol object to a SMILES string\n",
        "    smiles = Chem.MolToSmiles(mol)\n",
        "    generated_smiles= smiles\n",
        "\n",
        "    print(\"SMILES:\", smiles)\n",
        "\n",
        "\n",
        "    # Check if the molecule is valid (i.e., if it has correct atom types, valence, etc.)\n",
        "    def is_valid_molecule(mol):\n",
        "        if mol is None:\n",
        "            return False\n",
        "        return Chem.SanitizeMol(mol) == Chem.SanitizeFlags.SANITIZE_NONE\n",
        "\n",
        "    # Example usage:\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    valid = is_valid_molecule(mol)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    print(valid)\n",
        "    import torch\n",
        "    import networkx as nx\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    # Given adjacency matrix (renamed as adj_matrix)\n",
        "    adj_matrix = adjacency_matrix_dec\n",
        "\n",
        "    # Convert adj_matrix to NumPy array and then to NetworkX graph\n",
        "    G = nx.from_numpy_array(adj_matrix.numpy())\n",
        "\n",
        "    # Draw the graph\n",
        "    pos = nx.spring_layout(G, seed=42)  # Layout for graph visualization\n",
        "    nx.draw(G, pos, with_labels=True, node_color='lightblue', node_size=1000, font_size=12, font_weight='bold')\n",
        "    plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 811
        },
        "id": "BvfMXH2eZRpc",
        "outputId": "f9c77232-2393-4402-9788-d6c101635be2"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "sampling loop time step: 100%|██████████| 50/50 [00:00<00:00, 288.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result:\n",
            "tensor([[0., 0., 1., 0., 0.],\n",
            "        [0., 0., 1., 0., 0.],\n",
            "        [0., 0., 1., 0., 0.],\n",
            "        [0., 0., 1., 0., 0.]])\n",
            "New Tensor:\n",
            "tensor([7, 7, 7, 7])\n",
            "tensor([[0, 1, 0, 1],\n",
            "        [1, 0, 0, 1],\n",
            "        [0, 0, 0, 1],\n",
            "        [1, 1, 1, 0]], dtype=torch.int32)\n",
            "Edge Index:\n",
            "tensor([[0, 0, 1, 1, 2, 3, 3, 3],\n",
            "        [1, 3, 0, 3, 3, 0, 1, 2]])\n",
            "SMILES: NN1NN1\n",
            "True\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tyenQRC9ZRsC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}